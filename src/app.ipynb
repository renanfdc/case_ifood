{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFTDBtwzTX5o"
      },
      "source": [
        "1-Download da fonte de dados e armazenamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2NN8wwF7YRa"
      },
      "outputs": [],
      "source": [
        "# === RAW INGESTION: Download de arquivos públicos e envio para o bucket GCS ===\n",
        "\n",
        "from google.cloud import storage\n",
        "import requests, io\n",
        "\n",
        "# Configurações do projeto e bucket\n",
        "PROJECT_ID  = \"potent-poetry-295317\"\n",
        "BUCKET_NAME = \"teste_ifood_nyc\"\n",
        "RAW_PREFIX  = \"nyc_tlc_raw\"  # Prefixo raiz da camada raw no bucket\n",
        "BASE_URL    = \"https://d37ci6vzurychx.cloudfront.net/trip-data\"  # Fonte pública de dados\n",
        "\n",
        "# Escopo da ingestão (ano, meses e tipos de serviço)\n",
        "YEARS  = [2023]\n",
        "MONTHS = [1, 2, 3, 4, 5]  # Janeiro a Maio\n",
        "TYPES  = [\"yellow\", \"green\", \"fhv\", \"fhvhv\"]\n",
        "\n",
        "# Inicializa o cliente GCS e acessa o bucket\n",
        "gcs = storage.Client(project=PROJECT_ID)\n",
        "bucket = gcs.bucket(BUCKET_NAME)\n",
        "\n",
        "# Valida existência do bucket\n",
        "if not bucket.exists():\n",
        "    raise RuntimeError(f\"Bucket '{BUCKET_NAME}' não existe no projeto '{PROJECT_ID}'\")\n",
        "\n",
        "# Função para enviar conteúdo binário para o GCS\n",
        "def upload_bytes(path: str, content: bytes):\n",
        "    blob = bucket.blob(path)\n",
        "    blob.upload_from_file(io.BytesIO(content), rewind=True)\n",
        "    print(f\"Arquivo enviado para: gs://{BUCKET_NAME}/{path}\")\n",
        "\n",
        "# Função que faz download do arquivo público e envia para o GCS\n",
        "def fetch_and_push(filetype: str, year: int, month: int):\n",
        "    mm = f\"{month:02d}\"\n",
        "    src_url = f\"{BASE_URL}/{filetype}_tripdata_{year}-{mm}.parquet\"\n",
        "    dst_path = f\"{RAW_PREFIX}/{year}/{mm}/{filetype}_tripdata_{year}-{mm}.parquet\"\n",
        "\n",
        "    print(f\"Processando: {src_url} → gs://{BUCKET_NAME}/{dst_path}\")\n",
        "    r = requests.get(src_url, timeout=120)\n",
        "    r.raise_for_status()\n",
        "    upload_bytes(dst_path, r.content)\n",
        "\n",
        "# Loop principal que faz a ingestão para cada combinação de tipo, ano e mês\n",
        "for y in YEARS:\n",
        "    for m in MONTHS:\n",
        "        for t in TYPES:\n",
        "            try:\n",
        "                fetch_and_push(t, y, m)\n",
        "            except Exception as e:\n",
        "                print(f\"Aviso: falha ao processar {t} {y}-{m:02d}: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc_i-l5JXrYp"
      },
      "source": [
        "2-Criação dos Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PdoNOadXpjV",
        "outputId": "2b5aeaf4-9a80-424b-d0ab-52f47e93d295"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# === CONFIGURAÇÃO DO PROJETO E LOCALIZAÇÃO ===\n",
        "PROJECT  = \"potent-poetry-295317\"\n",
        "LOCATION = \"us-east1\"  # Região onde os datasets serão criados\n",
        "\n",
        "# Inicializa o cliente do BigQuery\n",
        "bq_client = bigquery.Client(project=PROJECT)\n",
        "\n",
        "# Lista de datasets a serem criados (bronze, silver, gold)\n",
        "datasets = [\n",
        "    f\"{PROJECT}.nyc_tlc_bronze\",\n",
        "    f\"{PROJECT}.nyc_tlc_silver\",\n",
        "    f\"{PROJECT}.nyc_tlc_gold\"\n",
        "]\n",
        "\n",
        "# Criação dos datasets com descrição e localização\n",
        "for ds_id in datasets:\n",
        "    ds = bigquery.Dataset(ds_id)\n",
        "    ds.location = LOCATION\n",
        "    ds.description = f\"Camada {ds_id.split('_')[-1].upper()} do case NYC TLC.\"\n",
        "\n",
        "    # Cria o dataset se não existir\n",
        "    bq_client.create_dataset(ds, exists_ok=True)\n",
        "    print(f\"Dataset criado ou existente: {ds_id} (location: {LOCATION})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgrAqg1gZHqQ"
      },
      "source": [
        "3-Criação da Sessão Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFnlDeM5ZK_o"
      },
      "outputs": [],
      "source": [
        "# Inicia sessão Spark Serverless (via Spark Connect no GCP)\n",
        "from google.cloud.dataproc_spark_connect import DataprocSparkSession\n",
        "\n",
        "spark = DataprocSparkSession.builder.getOrCreate()\n",
        "print(\"Spark inicializado. Versão:\", spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8O8iFHC1lrv"
      },
      "source": [
        "4-Ingestão Camada Staging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_qimFq4q4RJ"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from google.cloud import storage\n",
        "\n",
        "# Configurações gerais\n",
        "PROJECT_ID   = \"potent-poetry-295317\"\n",
        "BUCKET_NAME  = \"teste_ifood_nyc\"\n",
        "RAW_PREFIX   = \"nyc_tlc_raw\"\n",
        "STG_PREFIX   = \"nyc_tlc_staging\"\n",
        "\n",
        "YEARS  = [2023]\n",
        "MONTHS = [1, 2, 3, 4, 5]\n",
        "TYPES  = [\"yellow\", \"green\", \"fhv\", \"fhvhv\"]\n",
        "\n",
        "# Cliente GCS para acesso ao bucket\n",
        "gcs = storage.Client(project=PROJECT_ID)\n",
        "bucket = gcs.bucket(BUCKET_NAME)\n",
        "\n",
        "# Função de normalização por tipo de dado\n",
        "def normalize_by_type(df, t):\n",
        "    def has(c): return c in df.columns\n",
        "\n",
        "    if t == \"yellow\":\n",
        "        pickup  = F.col(\"tpep_pickup_datetime\") if has(\"tpep_pickup_datetime\") else F.lit(None)\n",
        "        dropoff = F.col(\"tpep_dropoff_datetime\") if has(\"tpep_dropoff_datetime\") else F.lit(None)\n",
        "        vendor  = F.col(\"VendorID\") if has(\"VendorID\") else (F.col(\"vendorid\") if has(\"vendorid\") else F.lit(None))\n",
        "        passeng = F.col(\"passenger_count\") if has(\"passenger_count\") else F.lit(None)\n",
        "        total   = F.col(\"total_amount\") if has(\"total_amount\") else F.lit(None)\n",
        "\n",
        "    elif t == \"green\":\n",
        "        pickup  = F.col(\"lpep_pickup_datetime\") if has(\"lpep_pickup_datetime\") else F.lit(None)\n",
        "        dropoff = F.col(\"lpep_dropoff_datetime\") if has(\"lpep_dropoff_datetime\") else F.lit(None)\n",
        "        vendor  = F.col(\"VendorID\") if has(\"VendorID\") else (F.col(\"vendorid\") if has(\"vendorid\") else F.lit(None))\n",
        "        passeng = F.col(\"passenger_count\") if has(\"passenger_count\") else F.lit(None)\n",
        "        total   = F.col(\"total_amount\") if has(\"total_amount\") else F.lit(None)\n",
        "\n",
        "    elif t == \"fhv\":\n",
        "        pickup  = F.col(\"pickup_datetime\") if has(\"pickup_datetime\") else F.lit(None)\n",
        "        dropoff = F.col(\"dropOff_datetime\") if has(\"dropOff_datetime\") else F.lit(None)\n",
        "        return df.select(\n",
        "            F.to_timestamp(pickup).alias(\"tpep_pickup_datetime\"),\n",
        "            F.to_timestamp(dropoff).alias(\"tpep_dropoff_datetime\")\n",
        "        )\n",
        "\n",
        "    elif t == \"fhvhv\":\n",
        "        pickup  = F.col(\"pickup_datetime\") if has(\"pickup_datetime\") else F.lit(None)\n",
        "        dropoff = F.col(\"dropoff_datetime\") if has(\"dropoff_datetime\") else F.lit(None)\n",
        "        return df.select(\n",
        "            F.to_timestamp(pickup).alias(\"tpep_pickup_datetime\"),\n",
        "            F.to_timestamp(dropoff).alias(\"tpep_dropoff_datetime\")\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        return df.select(\n",
        "            F.lit(None).cast(\"timestamp\").alias(\"tpep_pickup_datetime\"),\n",
        "            F.lit(None).cast(\"timestamp\").alias(\"tpep_dropoff_datetime\")\n",
        "        )\n",
        "\n",
        "    # Para yellow e green\n",
        "    return df.select(\n",
        "        vendor.cast(\"int\").alias(\"VendorID\"),\n",
        "        passeng.cast(\"int\").alias(\"passenger_count\"),\n",
        "        total.cast(\"double\").alias(\"total_amount\"),\n",
        "        F.to_timestamp(pickup).alias(\"tpep_pickup_datetime\"),\n",
        "        F.to_timestamp(dropoff).alias(\"tpep_dropoff_datetime\")\n",
        "    )\n",
        "\n",
        "# Função que move o arquivo gerado da pasta temporária para a pasta final\n",
        "def promote_tmp_to_single_file(tmp_prefix: str, final_blob_name: str):\n",
        "    part = None\n",
        "    for b in bucket.list_blobs(prefix=tmp_prefix):\n",
        "        tail = b.name.rsplit(\"/\", 1)[-1]\n",
        "        if tail.startswith(\"part-\") and tail.endswith(\".parquet\"):\n",
        "            part = b\n",
        "            break\n",
        "\n",
        "    if not part:\n",
        "        raise RuntimeError(f\"Arquivo part-*.parquet não encontrado em gs://{BUCKET_NAME}/{tmp_prefix}\")\n",
        "\n",
        "    bucket.copy_blob(part, bucket, new_name=final_blob_name)\n",
        "\n",
        "    # Remove arquivos temporários após promoção\n",
        "    for b in bucket.list_blobs(prefix=tmp_prefix):\n",
        "        b.delete()\n",
        "\n",
        "# Processo principal de leitura, normalização e escrita\n",
        "def main():\n",
        "    for y in YEARS:\n",
        "        for m in MONTHS:\n",
        "            for t in TYPES:\n",
        "                raw_path   = f\"gs://{BUCKET_NAME}/{RAW_PREFIX}/{y}/{m:02d}/{t}_tripdata_{y}-{m:02d}.parquet\"\n",
        "                tmp_prefix = f\"{STG_PREFIX}/{y}/{m:02d}/{t}_tripdata_{y}-{m:02d}.parquet_tmp/\"\n",
        "                final_blob = f\"{STG_PREFIX}/{y}/{m:02d}/{t}_tripdata_{y}-{m:02d}.parquet\"\n",
        "\n",
        "                try:\n",
        "                    print(f\"Processando: {t} {y}-{m:02d}\")\n",
        "                    df_raw = spark.read.parquet(raw_path)\n",
        "                    df_stg = normalize_by_type(df_raw, t)\n",
        "\n",
        "                    # Verifica consistência entre raw e staging\n",
        "                    raw_count = df_raw.count()\n",
        "                    stg_count = df_stg.count()\n",
        "\n",
        "                    if raw_count != stg_count:\n",
        "                        print(f\"Aviso: {t} {y}-{m:02d} - raw: {raw_count} linhas ≠ staging: {stg_count} linhas\")\n",
        "                    else:\n",
        "                        print(f\"Linhas OK: {t} {y}-{m:02d} - {raw_count} linhas\")\n",
        "\n",
        "                    # Escreve no GCS em modo overwrite\n",
        "                    df_stg.coalesce(1).write.mode(\"overwrite\").parquet(f\"gs://{BUCKET_NAME}/{tmp_prefix}\")\n",
        "                    promote_tmp_to_single_file(tmp_prefix, final_blob)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Erro ao processar {t} {y}-{m:02d}: {e}\")\n",
        "\n",
        "# Execução do processo\n",
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3wbcb62jQps"
      },
      "source": [
        "5-Ingestão Camada Bronze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "collapsed": true,
        "id": "9lIekYoQ5_Sb",
        "outputId": "b2889364-2d4d-45cb-bc99-0e98183fa728"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# === CONFIGURAÇÕES GERAIS ===\n",
        "PROJECT_ID  = \"potent-poetry-295317\"\n",
        "DATASET_ID  = \"nyc_tlc_bronze\"\n",
        "BUCKET_NAME = \"teste_ifood_nyc\"\n",
        "STG_PREFIX  = \"nyc_tlc_staging\"\n",
        "TYPES       = [\"yellow\", \"green\", \"fhv\", \"fhvhv\"]\n",
        "\n",
        "bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# === SCHEMAS COM DESCRIÇÕES (aparecem no esquema do BigQuery) ===\n",
        "schemas = {\n",
        "    \"yellow\": [\n",
        "        bigquery.SchemaField(\"VendorID\", \"INTEGER\",\n",
        "            description=\"Código do provedor: 1=Creative Mobile Technologies, 2=Curb Mobility, 6=Myle Technologies.\"),\n",
        "        bigquery.SchemaField(\"passenger_count\", \"INTEGER\",\n",
        "            description=\"Número de passageiros na corrida.\"),\n",
        "        bigquery.SchemaField(\"total_amount\", \"FLOAT\",\n",
        "            description=\"Valor total da corrida (taxas e gorjetas incluídas).\"),\n",
        "        bigquery.SchemaField(\"tpep_pickup_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de início da corrida.\"),\n",
        "        bigquery.SchemaField(\"tpep_dropoff_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de término da corrida.\"),\n",
        "    ],\n",
        "    \"green\": [\n",
        "        bigquery.SchemaField(\"VendorID\", \"INTEGER\",\n",
        "            description=\"Código do provedor (1, 2 ou 6).\"),\n",
        "        bigquery.SchemaField(\"passenger_count\", \"INTEGER\",\n",
        "            description=\"Quantidade de passageiros.\"),\n",
        "        bigquery.SchemaField(\"total_amount\", \"FLOAT\",\n",
        "            description=\"Valor total pago.\"),\n",
        "        bigquery.SchemaField(\"tpep_pickup_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de início da corrida.\"),\n",
        "        bigquery.SchemaField(\"tpep_dropoff_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de término da corrida.\"),\n",
        "    ],\n",
        "    \"fhv\": [\n",
        "        bigquery.SchemaField(\"tpep_pickup_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de início da viagem FHV.\"),\n",
        "        bigquery.SchemaField(\"tpep_dropoff_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de término da viagem FHV.\"),\n",
        "    ],\n",
        "    \"fhvhv\": [\n",
        "        bigquery.SchemaField(\"tpep_pickup_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de início da viagem FHVHV.\"),\n",
        "        bigquery.SchemaField(\"tpep_dropoff_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de término da viagem FHVHV.\"),\n",
        "    ],\n",
        "}\n",
        "\n",
        "# === NORMALIZAÇÃO MÍNIMA POR TIPO (apenas tipos e nomes) ===\n",
        "def normalize_by_type(df, t: str):\n",
        "    if t in [\"yellow\", \"green\"]:\n",
        "        return df.select(\n",
        "            F.col(\"VendorID\").cast(\"int\").alias(\"VendorID\"),\n",
        "            F.col(\"passenger_count\").cast(\"int\").alias(\"passenger_count\"),\n",
        "            F.col(\"total_amount\").cast(\"double\").alias(\"total_amount\"),\n",
        "            F.col(\"tpep_pickup_datetime\").cast(\"timestamp\").alias(\"tpep_pickup_datetime\"),\n",
        "            F.col(\"tpep_dropoff_datetime\").cast(\"timestamp\").alias(\"tpep_dropoff_datetime\"),\n",
        "        )\n",
        "    else:  # fhv / fhvhv\n",
        "        return df.select(\n",
        "            F.col(\"tpep_pickup_datetime\").cast(\"timestamp\").alias(\"tpep_pickup_datetime\"),\n",
        "            F.col(\"tpep_dropoff_datetime\").cast(\"timestamp\").alias(\"tpep_dropoff_datetime\"),\n",
        "        )\n",
        "\n",
        "# === CRIA/RECRIA TABELA COM DESCRIÇÕES, PARTICIONAMENTO E CLUSTERIZAÇÃO ===\n",
        "def create_table_with_schema(t: str):\n",
        "    table_id = f\"{PROJECT_ID}.{DATASET_ID}.tbl_{t}_bronze\"\n",
        "    table = bigquery.Table(table_id, schema=schemas[t])\n",
        "    table.description = f\"Tabela BRONZE {t.upper()} normalizada a partir da staging (tipos e nomes padronizados).\"\n",
        "    table.time_partitioning = bigquery.TimePartitioning(\n",
        "        type_=bigquery.TimePartitioningType.MONTH, field=\"tpep_pickup_datetime\"\n",
        "    )\n",
        "    if t in [\"yellow\", \"green\"]:\n",
        "        table.clustering_fields = [\"VendorID\"]\n",
        "\n",
        "    # recria para garantir que descrições/partitioning/cluster estejam atualizados\n",
        "    bq_client.delete_table(table_id, not_found_ok=True)\n",
        "    bq_client.create_table(table)\n",
        "    print(f\"🆕 Tabela criada: {table_id}\")\n",
        "\n",
        "# === PIPELINE: LER STAGING → NORMALIZAR → CRIAR TABELA → GRAVAR NO BQ ===\n",
        "for t in TYPES:\n",
        "    try:\n",
        "        print(f\"\\n🔄 Processando tipo: {t}\")\n",
        "        path = f\"gs://{BUCKET_NAME}/{STG_PREFIX}/2023/*/{t}_tripdata_*.parquet\"\n",
        "        df_raw = spark.read.parquet(path)\n",
        "\n",
        "        df_bronze = normalize_by_type(df_raw, t)\n",
        "        print(f\"Total de linhas ({t}): {df_bronze.count()}\")\n",
        "\n",
        "        create_table_with_schema(t)\n",
        "\n",
        "        writer = (\n",
        "            df_bronze.write\n",
        "            .format(\"bigquery\")\n",
        "            .option(\"table\", f\"{PROJECT_ID}.{DATASET_ID}.tbl_{t}_bronze\")\n",
        "            .option(\"writeMethod\", \"direct\")\n",
        "            .mode(\"overwrite\")  # substitui os dados; a estrutura/descrições ficam\n",
        "        )\n",
        "        if t in [\"yellow\", \"green\"]:\n",
        "            writer = writer.option(\"clusteredFields\", \"VendorID\") \\\n",
        "                           .option(\"partitionField\", \"tpep_pickup_datetime\") \\\n",
        "                           .option(\"partitionType\", \"MONTH\")\n",
        "\n",
        "        writer.save()\n",
        "        print(f\"Dados gravados: {PROJECT_ID}.{DATASET_ID}.tbl_{t}_bronze\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao processar {t}: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxTQHRZVl-wK"
      },
      "source": [
        "6-Ingestão Camada Silver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fL-Dp7YdXVR"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=\"potent-poetry-295317\")\n",
        "\n",
        "bronze = \"potent-poetry-295317.nyc_tlc_bronze\"\n",
        "silver = \"potent-poetry-295317.nyc_tlc_silver\"\n",
        "\n",
        "# Descrições por tabela\n",
        "descriptions = {\n",
        "    \"yellow\": \"Tabela Silver com dados tratados dos táxis amarelos (Yellow Cabs) de NYC.\",\n",
        "    \"green\": \"Tabela Silver com dados tratados dos táxis verdes (Green Cabs) de NYC.\",\n",
        "    \"fhv\": \"Tabela Silver com dados tratados dos veículos FHV (For-Hire Vehicles).\",\n",
        "    \"fhvhv\": \"Tabela Silver com dados tratados dos veículos FHVHV (High Volume FHV).\"\n",
        "}\n",
        "\n",
        "# Descrições por coluna separadas por tabela\n",
        "column_descriptions_by_table = {\n",
        "    \"yellow\": {\n",
        "        \"datetime_pickup\": \"Data e hora de início da corrida.\",\n",
        "        \"datetime_dropoff\": \"Data e hora de término da corrida.\",\n",
        "        \"count_passenger\": \"Quantidade de passageiros transportados na corrida.\",\n",
        "        \"id_vendor\": \"Código da empresa de táxi que providenciou a corrida.\",\n",
        "        \"nm_vendor\": \"Nome da empresa correspondente ao VendorID.\",\n",
        "        \"vl_amount\": \"Valor total pago pela corrida, incluindo taxas e gorjetas.\",\n",
        "        \"minutes_duration_trip\": \"Duração da corrida em minutos.\"\n",
        "    },\n",
        "    \"green\": {\n",
        "        \"datetime_pickup\": \"Data e hora de início da corrida.\",\n",
        "        \"datetime_dropoff\": \"Data e hora de término da corrida.\",\n",
        "        \"count_passenger\": \"Quantidade de passageiros transportados na corrida.\",\n",
        "        \"id_vendor\": \"Código da empresa de táxi que providenciou a corrida.\",\n",
        "        \"nm_vendor\": \"Nome da empresa correspondente ao VendorID.\",\n",
        "        \"vl_amount\": \"Valor total pago pela corrida, incluindo taxas e gorjetas.\",\n",
        "        \"minutes_duration_trip\": \"Duração da corrida em minutos.\"\n",
        "    },\n",
        "    \"fhv\": {\n",
        "        \"datetime_pickup\": \"Data e hora de início da corrida.\",\n",
        "        \"datetime_dropoff\": \"Data e hora de término da corrida.\",\n",
        "        \"minutes_duration_trip\": \"Duração da corrida em minutos.\"\n",
        "    },\n",
        "    \"fhvhv\": {\n",
        "        \"datetime_pickup\": \"Data e hora de início da corrida.\",\n",
        "        \"datetime_dropoff\": \"Data e hora de término da corrida.\",\n",
        "        \"minutes_duration_trip\": \"Duração da corrida em minutos.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Queries para recriar tabelas Silver\n",
        "queries = {\n",
        "    \"yellow\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {silver}.tbl_yellow_silver\n",
        "        PARTITION BY DATE(datetime_pickup)\n",
        "        CLUSTER BY id_vendor\n",
        "        OPTIONS(description=\\\"{descriptions['yellow']}\\\") AS\n",
        "        SELECT\n",
        "            CAST(tpep_pickup_datetime AS TIMESTAMP) AS datetime_pickup,\n",
        "            CAST(tpep_dropoff_datetime AS TIMESTAMP) AS datetime_dropoff,\n",
        "            IF(passenger_count < 0, 0, CAST(passenger_count AS INT64)) AS count_passenger,\n",
        "            CAST(VendorID AS INT64) AS id_vendor,\n",
        "            CASE\n",
        "                WHEN VendorID = 1 THEN 'Creative Mobile Technologies, LLC'\n",
        "                WHEN VendorID = 2 THEN 'Curb Mobility, LLC'\n",
        "                WHEN VendorID = 6 THEN 'Myle Technologies Inc.'\n",
        "                ELSE 'Desconhecido'\n",
        "            END AS nm_vendor,\n",
        "            IFNULL(CAST(total_amount AS FLOAT64), 0.0) AS vl_amount,\n",
        "            ROUND(TIMESTAMP_DIFF(tpep_dropoff_datetime, tpep_pickup_datetime, SECOND) / 60, 2) AS minutes_duration_trip\n",
        "        FROM {bronze}.tbl_yellow_bronze\n",
        "        WHERE DATE(tpep_pickup_datetime) BETWEEN '2023-01-01' AND '2023-05-31'\n",
        "    \"\"\",\n",
        "\n",
        "    \"green\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {silver}.tbl_green_silver\n",
        "        PARTITION BY DATE(datetime_pickup)\n",
        "        CLUSTER BY id_vendor\n",
        "        OPTIONS(description=\\\"{descriptions['green']}\\\") AS\n",
        "        SELECT\n",
        "            CAST(tpep_pickup_datetime AS TIMESTAMP) AS datetime_pickup,\n",
        "            CAST(tpep_dropoff_datetime AS TIMESTAMP) AS datetime_dropoff,\n",
        "            IF(passenger_count < 0, 0, CAST(passenger_count AS INT64)) AS count_passenger,\n",
        "            CAST(VendorID AS INT64) AS id_vendor,\n",
        "            CASE\n",
        "                WHEN VendorID = 1 THEN 'Creative Mobile Technologies, LLC'\n",
        "                WHEN VendorID = 2 THEN 'Curb Mobility, LLC'\n",
        "                WHEN VendorID = 6 THEN 'Myle Technologies Inc.'\n",
        "                ELSE 'Desconhecido'\n",
        "            END AS nm_vendor,\n",
        "            IFNULL(CAST(total_amount AS FLOAT64), 0.0) AS vl_amount,\n",
        "            ROUND(TIMESTAMP_DIFF(tpep_dropoff_datetime, tpep_pickup_datetime, SECOND) / 60, 2) AS minutes_duration_trip\n",
        "        FROM {bronze}.tbl_green_bronze\n",
        "        WHERE DATE(tpep_pickup_datetime) BETWEEN '2023-01-01' AND '2023-05-31'\n",
        "    \"\"\",\n",
        "\n",
        "    \"fhv\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {silver}.tbl_fhv_silver\n",
        "        PARTITION BY DATE(datetime_pickup)\n",
        "        OPTIONS(description=\\\"{descriptions['fhv']}\\\") AS\n",
        "        SELECT\n",
        "            CAST(tpep_pickup_datetime AS TIMESTAMP) AS datetime_pickup,\n",
        "            CAST(tpep_dropoff_datetime AS TIMESTAMP) AS datetime_dropoff,\n",
        "            ROUND(TIMESTAMP_DIFF(tpep_dropoff_datetime, tpep_pickup_datetime, SECOND) / 60, 2) AS minutes_duration_trip\n",
        "        FROM {bronze}.tbl_fhv_bronze\n",
        "        WHERE DATE(tpep_pickup_datetime) BETWEEN '2023-01-01' AND '2023-05-31'\n",
        "    \"\"\",\n",
        "\n",
        "    \"fhvhv\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {silver}.tbl_fhvhv_silver\n",
        "        PARTITION BY DATE(datetime_pickup)\n",
        "        OPTIONS(description=\\\"{descriptions['fhvhv']}\\\") AS\n",
        "        SELECT\n",
        "            CAST(tpep_pickup_datetime AS TIMESTAMP) AS datetime_pickup,\n",
        "            CAST(tpep_dropoff_datetime AS TIMESTAMP) AS datetime_dropoff,\n",
        "            ROUND(TIMESTAMP_DIFF(tpep_dropoff_datetime, tpep_pickup_datetime, SECOND) / 60, 2) AS minutes_duration_trip\n",
        "        FROM {bronze}.tbl_fhvhv_bronze\n",
        "        WHERE DATE(tpep_pickup_datetime) BETWEEN '2023-01-01' AND '2023-05-31'\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "# Executa criação + update de descrições de colunas\n",
        "for tipo, query in queries.items():\n",
        "    table_id = f\"{silver}.tbl_{tipo}_silver\"\n",
        "    print(f\"Recriando tabela Silver para: {tipo}\")\n",
        "\n",
        "    client.delete_table(table_id, not_found_ok=True)\n",
        "    print(f\"Tabela deletada (se existia): {table_id}\")\n",
        "\n",
        "    client.query(query).result()\n",
        "    print(f\"Tabela {table_id} criada com sucesso.\")\n",
        "\n",
        "    table = client.get_table(table_id)\n",
        "    new_schema = []\n",
        "    column_descriptions = column_descriptions_by_table.get(tipo, {})\n",
        "    for field in table.schema:\n",
        "        desc = column_descriptions.get(field.name, field.description)\n",
        "        new_schema.append(bigquery.SchemaField(field.name, field.field_type, mode=field.mode, description=desc))\n",
        "    table.schema = new_schema\n",
        "    client.update_table(table, [\"schema\"])\n",
        "    print(f\"Descrições de colunas aplicadas para {table_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p9l4uGcHMYB"
      },
      "source": [
        "6-Ingestão Camada Gold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCrcLpA6h97c",
        "outputId": "093e7cb2-704d-49ee-b78b-298460810911"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=\"potent-poetry-295317\")\n",
        "\n",
        "silver = \"potent-poetry-295317.nyc_tlc_silver\"\n",
        "gold = \"potent-poetry-295317.nyc_tlc_gold\"\n",
        "\n",
        "# Descrições por coluna por tabela\n",
        "column_descriptions_by_table = {\n",
        "    \"tbl_yellow_gold\": {\n",
        "        \"datetime_pickup\": \"Data e hora de início da corrida.\",\n",
        "        \"month_reference\": \"Mês e ano da corrida (primeiro dia do mês).\",\n",
        "        \"avg_vl_amount\": \"Valor médio total pago por corrida.\",\n",
        "        \"count_rides\": \"Número total de corridas no dia.\",\n",
        "        \"avg_minutes_duration\": \"Duração média das corridas no dia (em minutos).\"\n",
        "    },\n",
        "    \"tbl_green_gold\": {\n",
        "        \"datetime_pickup\": \"Data e hora de início da corrida.\",\n",
        "        \"month_reference\": \"Mês e ano da corrida (primeiro dia do mês).\",\n",
        "        \"avg_vl_amount\": \"Valor médio total pago por corrida.\",\n",
        "        \"count_rides\": \"Número total de corridas no dia.\",\n",
        "        \"avg_minutes_duration\": \"Duração média das corridas no dia (em minutos).\"\n",
        "    },\n",
        "    \"tbl_fhv_gold\": {\n",
        "        \"datetime_pickup\": \"Data e hora de início da corrida.\",\n",
        "        \"month_reference\": \"Mês e ano da corrida (primeiro dia do mês).\",\n",
        "        \"count_rides\": \"Número total de corridas no dia.\",\n",
        "        \"avg_minutes_duration\": \"Duração média das corridas no dia (em minutos).\"\n",
        "    },\n",
        "    \"tbl_fhvhv_gold\": {\n",
        "        \"datetime_pickup\": \"Data e hora de início da corrida.\",\n",
        "        \"month_reference\": \"Mês e ano da corrida (primeiro dia do mês).\",\n",
        "        \"count_rides\": \"Número total de corridas no dia.\",\n",
        "        \"avg_minutes_duration\": \"Duração média das corridas no dia (em minutos).\"\n",
        "    },\n",
        "    \"tbl_passenger_hour_gold\": {\n",
        "        \"datetime_pickup\": \"Data e hora de início da corrida.\",\n",
        "        \"date_reference\": \"Data da corrida.\",\n",
        "        \"month_reference\": \"Mês e ano de referência (primeiro dia do mês).\",\n",
        "        \"hour_trip\": \"Hora do dia formatada no formato HH:00 (24h) em que a corrida iniciou.\",\n",
        "        \"type_service\": \"Tipo de serviço (yellow ou green).\",\n",
        "        \"avg_count_passenger\": \"Média de passageiros por corrida naquela hora.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "descriptions = {\n",
        "    \"tbl_yellow_gold\": \"Tabela Gold com métricas agregadas por corrida dos táxis amarelos.\",\n",
        "    \"tbl_green_gold\": \"Tabela Gold com métricas agregadas por corrida dos táxis verdes.\",\n",
        "    \"tbl_fhv_gold\": \"Tabela Gold com métricas agregadas dos veículos FHV.\",\n",
        "    \"tbl_fhvhv_gold\": \"Tabela Gold com métricas agregadas dos veículos FHVHV.\",\n",
        "    \"tbl_passenger_hour_gold\": \"Tabela Gold com média de passageiros por hora no mês de maio.\"\n",
        "}\n",
        "\n",
        "queries = {\n",
        "    \"tbl_yellow_gold\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {gold}.tbl_yellow_gold\n",
        "        PARTITION BY DATE_TRUNC(datetime_pickup, MONTH)\n",
        "        OPTIONS(description=\\\"{descriptions['tbl_yellow_gold']}\\\") AS\n",
        "        SELECT\n",
        "            datetime_pickup,\n",
        "            DATE_TRUNC(datetime_pickup, MONTH) AS month_reference,\n",
        "            ROUND(AVG(vl_amount), 2) AS avg_vl_amount,\n",
        "            COUNT(*) AS count_rides,\n",
        "            ROUND(AVG(minutes_duration_trip), 2) AS avg_minutes_duration\n",
        "        FROM {silver}.tbl_yellow_silver\n",
        "        GROUP BY datetime_pickup, month_reference\n",
        "    \"\"\",\n",
        "\n",
        "    \"tbl_green_gold\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {gold}.tbl_green_gold\n",
        "        PARTITION BY DATE_TRUNC(datetime_pickup, MONTH)\n",
        "        OPTIONS(description=\\\"{descriptions['tbl_green_gold']}\\\") AS\n",
        "        SELECT\n",
        "            datetime_pickup,\n",
        "            DATE_TRUNC(datetime_pickup, MONTH) AS month_reference,\n",
        "            ROUND(AVG(vl_amount), 2) AS avg_vl_amount,\n",
        "            COUNT(*) AS count_rides,\n",
        "            ROUND(AVG(minutes_duration_trip), 2) AS avg_minutes_duration\n",
        "        FROM {silver}.tbl_green_silver\n",
        "        GROUP BY datetime_pickup, month_reference\n",
        "    \"\"\",\n",
        "\n",
        "    \"tbl_fhv_gold\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {gold}.tbl_fhv_gold\n",
        "        PARTITION BY DATE_TRUNC(datetime_pickup, MONTH)\n",
        "        OPTIONS(description=\\\"{descriptions['tbl_fhv_gold']}\\\") AS\n",
        "        SELECT\n",
        "            datetime_pickup,\n",
        "            DATE_TRUNC(datetime_pickup, MONTH) AS month_reference,\n",
        "            COUNT(*) AS count_rides,\n",
        "            ROUND(AVG(minutes_duration_trip), 2) AS avg_minutes_duration\n",
        "        FROM {silver}.tbl_fhv_silver\n",
        "        GROUP BY datetime_pickup, month_reference\n",
        "    \"\"\",\n",
        "\n",
        "    \"tbl_fhvhv_gold\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {gold}.tbl_fhvhv_gold\n",
        "        PARTITION BY DATE_TRUNC(datetime_pickup, MONTH)\n",
        "        OPTIONS(description=\\\"{descriptions['tbl_fhvhv_gold']}\\\") AS\n",
        "        SELECT\n",
        "            datetime_pickup,\n",
        "            DATE_TRUNC(datetime_pickup, MONTH) AS month_reference,\n",
        "            COUNT(*) AS count_rides,\n",
        "            ROUND(AVG(minutes_duration_trip), 2) AS avg_minutes_duration\n",
        "        FROM {silver}.tbl_fhvhv_silver\n",
        "        GROUP BY datetime_pickup, month_reference\n",
        "    \"\"\",\n",
        "\n",
        "    \"tbl_passenger_hour_gold\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {gold}.tbl_passenger_hour_gold\n",
        "        PARTITION BY DATE(datetime_pickup)\n",
        "        CLUSTER BY type_service, hour_trip\n",
        "        OPTIONS(description=\\\"{descriptions['tbl_passenger_hour_gold']}\\\") AS\n",
        "        SELECT\n",
        "            datetime_pickup,\n",
        "            DATE(datetime_pickup) AS date_reference,\n",
        "            DATE_TRUNC(datetime_pickup, MONTH) AS month_reference,\n",
        "            LPAD(CAST(EXTRACT(HOUR FROM datetime_pickup) AS STRING), 2, '0') || ':00' AS hour_trip,\n",
        "            'yellow' AS type_service,\n",
        "            ROUND(AVG(count_passenger), 2) AS avg_count_passenger\n",
        "        FROM {silver}.tbl_yellow_silver\n",
        "        WHERE EXTRACT(MONTH FROM datetime_pickup) = 5\n",
        "        GROUP BY datetime_pickup, date_reference, month_reference, hour_trip\n",
        "\n",
        "        UNION ALL\n",
        "\n",
        "        SELECT\n",
        "            datetime_pickup,\n",
        "            DATE(datetime_pickup) AS date_reference,\n",
        "            DATE_TRUNC(datetime_pickup, MONTH) AS month_reference,\n",
        "            LPAD(CAST(EXTRACT(HOUR FROM datetime_pickup) AS STRING), 2, '0') || ':00' AS hour_trip,\n",
        "            'green' AS type_service,\n",
        "            ROUND(AVG(count_passenger), 2) AS avg_count_passenger\n",
        "        FROM {silver}.tbl_green_silver\n",
        "        WHERE EXTRACT(MONTH FROM datetime_pickup) = 5\n",
        "        GROUP BY datetime_pickup, date_reference, month_reference, hour_trip\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "for tbl, query in queries.items():\n",
        "    table_id = f\"{gold}.{tbl}\"\n",
        "    print(f\"Criando tabela GOLD: {table_id}\")\n",
        "\n",
        "    client.delete_table(table_id, not_found_ok=True)\n",
        "    print(f\"Tabela deletada (se existia): {table_id}\")\n",
        "\n",
        "    client.query(query).result()\n",
        "    print(f\"Tabela criada com sucesso: {table_id}\")\n",
        "\n",
        "    table = client.get_table(table_id)\n",
        "    schema = []\n",
        "    col_descriptions = column_descriptions_by_table.get(tbl, {})\n",
        "    for field in table.schema:\n",
        "        desc = col_descriptions.get(field.name, field.description)\n",
        "        schema.append(bigquery.SchemaField(field.name, field.field_type, mode=field.mode, description=desc))\n",
        "    table.schema = schema\n",
        "    client.update_table(table, [\"schema\"])\n",
        "    print(f\"Descrições de colunas atualizadas: {table_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HisZFRsn5_B4"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "name": "teste_ifood",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
