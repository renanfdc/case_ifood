{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFTDBtwzTX5o"
      },
      "source": [
        "1-Download da fonte de dados e armazenamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2NN8wwF7YRa"
      },
      "outputs": [],
      "source": [
        "# === RAW INGESTION: Download de arquivos p√∫blicos e envio para o bucket GCS ===\n",
        "\n",
        "from google.cloud import storage\n",
        "import requests, io\n",
        "\n",
        "# Configura√ß√µes do projeto e bucket\n",
        "PROJECT_ID  = \"potent-poetry-295317\"\n",
        "BUCKET_NAME = \"teste_ifood_nyc\"\n",
        "RAW_PREFIX  = \"nyc_tlc_raw\"  # Prefixo raiz da camada raw no bucket\n",
        "BASE_URL    = \"https://d37ci6vzurychx.cloudfront.net/trip-data\"  # Fonte p√∫blica de dados\n",
        "\n",
        "# Escopo da ingest√£o (ano, meses e tipos de servi√ßo)\n",
        "YEARS  = [2023]\n",
        "MONTHS = [1, 2, 3, 4, 5]  # Janeiro a Maio\n",
        "TYPES  = [\"yellow\", \"green\", \"fhv\", \"fhvhv\"]\n",
        "\n",
        "# Inicializa o cliente GCS e acessa o bucket\n",
        "gcs = storage.Client(project=PROJECT_ID)\n",
        "bucket = gcs.bucket(BUCKET_NAME)\n",
        "\n",
        "# Valida exist√™ncia do bucket\n",
        "if not bucket.exists():\n",
        "    raise RuntimeError(f\"Bucket '{BUCKET_NAME}' n√£o existe no projeto '{PROJECT_ID}'\")\n",
        "\n",
        "# Fun√ß√£o para enviar conte√∫do bin√°rio para o GCS\n",
        "def upload_bytes(path: str, content: bytes):\n",
        "    blob = bucket.blob(path)\n",
        "    blob.upload_from_file(io.BytesIO(content), rewind=True)\n",
        "    print(f\"Arquivo enviado para: gs://{BUCKET_NAME}/{path}\")\n",
        "\n",
        "# Fun√ß√£o que faz download do arquivo p√∫blico e envia para o GCS\n",
        "def fetch_and_push(filetype: str, year: int, month: int):\n",
        "    mm = f\"{month:02d}\"\n",
        "    src_url = f\"{BASE_URL}/{filetype}_tripdata_{year}-{mm}.parquet\"\n",
        "    dst_path = f\"{RAW_PREFIX}/{year}/{mm}/{filetype}_tripdata_{year}-{mm}.parquet\"\n",
        "\n",
        "    print(f\"Processando: {src_url} ‚Üí gs://{BUCKET_NAME}/{dst_path}\")\n",
        "    r = requests.get(src_url, timeout=120)\n",
        "    r.raise_for_status()\n",
        "    upload_bytes(dst_path, r.content)\n",
        "\n",
        "# Loop principal que faz a ingest√£o para cada combina√ß√£o de tipo, ano e m√™s\n",
        "for y in YEARS:\n",
        "    for m in MONTHS:\n",
        "        for t in TYPES:\n",
        "            try:\n",
        "                fetch_and_push(t, y, m)\n",
        "            except Exception as e:\n",
        "                print(f\"Aviso: falha ao processar {t} {y}-{m:02d}: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc_i-l5JXrYp"
      },
      "source": [
        "2-Cria√ß√£o dos Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PdoNOadXpjV",
        "outputId": "2b5aeaf4-9a80-424b-d0ab-52f47e93d295"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# === CONFIGURA√á√ÉO DO PROJETO E LOCALIZA√á√ÉO ===\n",
        "PROJECT  = \"potent-poetry-295317\"\n",
        "LOCATION = \"us-east1\"  # Regi√£o onde os datasets ser√£o criados\n",
        "\n",
        "# Inicializa o cliente do BigQuery\n",
        "bq_client = bigquery.Client(project=PROJECT)\n",
        "\n",
        "# Lista de datasets a serem criados (bronze, silver, gold)\n",
        "datasets = [\n",
        "    f\"{PROJECT}.nyc_tlc_bronze\",\n",
        "    f\"{PROJECT}.nyc_tlc_silver\",\n",
        "    f\"{PROJECT}.nyc_tlc_gold\"\n",
        "]\n",
        "\n",
        "# Cria√ß√£o dos datasets com descri√ß√£o e localiza√ß√£o\n",
        "for ds_id in datasets:\n",
        "    ds = bigquery.Dataset(ds_id)\n",
        "    ds.location = LOCATION\n",
        "    ds.description = f\"Camada {ds_id.split('_')[-1].upper()} do case NYC TLC.\"\n",
        "\n",
        "    # Cria o dataset se n√£o existir\n",
        "    bq_client.create_dataset(ds, exists_ok=True)\n",
        "    print(f\"Dataset criado ou existente: {ds_id} (location: {LOCATION})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgrAqg1gZHqQ"
      },
      "source": [
        "3-Cria√ß√£o da Sess√£o Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFnlDeM5ZK_o"
      },
      "outputs": [],
      "source": [
        "# Inicia sess√£o Spark Serverless (via Spark Connect no GCP)\n",
        "from google.cloud.dataproc_spark_connect import DataprocSparkSession\n",
        "\n",
        "spark = DataprocSparkSession.builder.getOrCreate()\n",
        "print(\"Spark inicializado. Vers√£o:\", spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8O8iFHC1lrv"
      },
      "source": [
        "4-Ingest√£o Camada Staging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_qimFq4q4RJ"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from google.cloud import storage\n",
        "\n",
        "# Configura√ß√µes gerais\n",
        "PROJECT_ID   = \"potent-poetry-295317\"\n",
        "BUCKET_NAME  = \"teste_ifood_nyc\"\n",
        "RAW_PREFIX   = \"nyc_tlc_raw\"\n",
        "STG_PREFIX   = \"nyc_tlc_staging\"\n",
        "\n",
        "YEARS  = [2023]\n",
        "MONTHS = [1, 2, 3, 4, 5]\n",
        "TYPES  = [\"yellow\", \"green\", \"fhv\", \"fhvhv\"]\n",
        "\n",
        "# Cliente GCS para acesso ao bucket\n",
        "gcs = storage.Client(project=PROJECT_ID)\n",
        "bucket = gcs.bucket(BUCKET_NAME)\n",
        "\n",
        "# Fun√ß√£o de normaliza√ß√£o por tipo de dado\n",
        "def normalize_by_type(df, t):\n",
        "    def has(c): return c in df.columns\n",
        "\n",
        "    if t == \"yellow\":\n",
        "        pickup  = F.col(\"tpep_pickup_datetime\") if has(\"tpep_pickup_datetime\") else F.lit(None)\n",
        "        dropoff = F.col(\"tpep_dropoff_datetime\") if has(\"tpep_dropoff_datetime\") else F.lit(None)\n",
        "        vendor  = F.col(\"VendorID\") if has(\"VendorID\") else (F.col(\"vendorid\") if has(\"vendorid\") else F.lit(None))\n",
        "        passeng = F.col(\"passenger_count\") if has(\"passenger_count\") else F.lit(None)\n",
        "        total   = F.col(\"total_amount\") if has(\"total_amount\") else F.lit(None)\n",
        "\n",
        "    elif t == \"green\":\n",
        "        pickup  = F.col(\"lpep_pickup_datetime\") if has(\"lpep_pickup_datetime\") else F.lit(None)\n",
        "        dropoff = F.col(\"lpep_dropoff_datetime\") if has(\"lpep_dropoff_datetime\") else F.lit(None)\n",
        "        vendor  = F.col(\"VendorID\") if has(\"VendorID\") else (F.col(\"vendorid\") if has(\"vendorid\") else F.lit(None))\n",
        "        passeng = F.col(\"passenger_count\") if has(\"passenger_count\") else F.lit(None)\n",
        "        total   = F.col(\"total_amount\") if has(\"total_amount\") else F.lit(None)\n",
        "\n",
        "    elif t == \"fhv\":\n",
        "        pickup  = F.col(\"pickup_datetime\") if has(\"pickup_datetime\") else F.lit(None)\n",
        "        dropoff = F.col(\"dropOff_datetime\") if has(\"dropOff_datetime\") else F.lit(None)\n",
        "        return df.select(\n",
        "            F.to_timestamp(pickup).alias(\"tpep_pickup_datetime\"),\n",
        "            F.to_timestamp(dropoff).alias(\"tpep_dropoff_datetime\")\n",
        "        )\n",
        "\n",
        "    elif t == \"fhvhv\":\n",
        "        pickup  = F.col(\"pickup_datetime\") if has(\"pickup_datetime\") else F.lit(None)\n",
        "        dropoff = F.col(\"dropoff_datetime\") if has(\"dropoff_datetime\") else F.lit(None)\n",
        "        return df.select(\n",
        "            F.to_timestamp(pickup).alias(\"tpep_pickup_datetime\"),\n",
        "            F.to_timestamp(dropoff).alias(\"tpep_dropoff_datetime\")\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        return df.select(\n",
        "            F.lit(None).cast(\"timestamp\").alias(\"tpep_pickup_datetime\"),\n",
        "            F.lit(None).cast(\"timestamp\").alias(\"tpep_dropoff_datetime\")\n",
        "        )\n",
        "\n",
        "    # Para yellow e green\n",
        "    return df.select(\n",
        "        vendor.cast(\"int\").alias(\"VendorID\"),\n",
        "        passeng.cast(\"int\").alias(\"passenger_count\"),\n",
        "        total.cast(\"double\").alias(\"total_amount\"),\n",
        "        F.to_timestamp(pickup).alias(\"tpep_pickup_datetime\"),\n",
        "        F.to_timestamp(dropoff).alias(\"tpep_dropoff_datetime\")\n",
        "    )\n",
        "\n",
        "# Fun√ß√£o que move o arquivo gerado da pasta tempor√°ria para a pasta final\n",
        "def promote_tmp_to_single_file(tmp_prefix: str, final_blob_name: str):\n",
        "    part = None\n",
        "    for b in bucket.list_blobs(prefix=tmp_prefix):\n",
        "        tail = b.name.rsplit(\"/\", 1)[-1]\n",
        "        if tail.startswith(\"part-\") and tail.endswith(\".parquet\"):\n",
        "            part = b\n",
        "            break\n",
        "\n",
        "    if not part:\n",
        "        raise RuntimeError(f\"Arquivo part-*.parquet n√£o encontrado em gs://{BUCKET_NAME}/{tmp_prefix}\")\n",
        "\n",
        "    bucket.copy_blob(part, bucket, new_name=final_blob_name)\n",
        "\n",
        "    # Remove arquivos tempor√°rios ap√≥s promo√ß√£o\n",
        "    for b in bucket.list_blobs(prefix=tmp_prefix):\n",
        "        b.delete()\n",
        "\n",
        "# Processo principal de leitura, normaliza√ß√£o e escrita\n",
        "def main():\n",
        "    for y in YEARS:\n",
        "        for m in MONTHS:\n",
        "            for t in TYPES:\n",
        "                raw_path   = f\"gs://{BUCKET_NAME}/{RAW_PREFIX}/{y}/{m:02d}/{t}_tripdata_{y}-{m:02d}.parquet\"\n",
        "                tmp_prefix = f\"{STG_PREFIX}/{y}/{m:02d}/{t}_tripdata_{y}-{m:02d}.parquet_tmp/\"\n",
        "                final_blob = f\"{STG_PREFIX}/{y}/{m:02d}/{t}_tripdata_{y}-{m:02d}.parquet\"\n",
        "\n",
        "                try:\n",
        "                    print(f\"Processando: {t} {y}-{m:02d}\")\n",
        "                    df_raw = spark.read.parquet(raw_path)\n",
        "                    df_stg = normalize_by_type(df_raw, t)\n",
        "\n",
        "                    # Verifica consist√™ncia entre raw e staging\n",
        "                    raw_count = df_raw.count()\n",
        "                    stg_count = df_stg.count()\n",
        "\n",
        "                    if raw_count != stg_count:\n",
        "                        print(f\"Aviso: {t} {y}-{m:02d} - raw: {raw_count} linhas ‚â† staging: {stg_count} linhas\")\n",
        "                    else:\n",
        "                        print(f\"Linhas OK: {t} {y}-{m:02d} - {raw_count} linhas\")\n",
        "\n",
        "                    # Escreve no GCS em modo overwrite\n",
        "                    df_stg.coalesce(1).write.mode(\"overwrite\").parquet(f\"gs://{BUCKET_NAME}/{tmp_prefix}\")\n",
        "                    promote_tmp_to_single_file(tmp_prefix, final_blob)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Erro ao processar {t} {y}-{m:02d}: {e}\")\n",
        "\n",
        "# Execu√ß√£o do processo\n",
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3wbcb62jQps"
      },
      "source": [
        "5-Ingest√£o Camada Bronze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "collapsed": true,
        "id": "9lIekYoQ5_Sb",
        "outputId": "b2889364-2d4d-45cb-bc99-0e98183fa728"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# === CONFIGURA√á√ïES GERAIS ===\n",
        "PROJECT_ID  = \"potent-poetry-295317\"\n",
        "DATASET_ID  = \"nyc_tlc_bronze\"\n",
        "BUCKET_NAME = \"teste_ifood_nyc\"\n",
        "STG_PREFIX  = \"nyc_tlc_staging\"\n",
        "TYPES       = [\"yellow\", \"green\", \"fhv\", \"fhvhv\"]\n",
        "\n",
        "bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# === SCHEMAS COM DESCRI√á√ïES (aparecem no esquema do BigQuery) ===\n",
        "schemas = {\n",
        "    \"yellow\": [\n",
        "        bigquery.SchemaField(\"VendorID\", \"INTEGER\",\n",
        "            description=\"C√≥digo do provedor: 1=Creative Mobile Technologies, 2=Curb Mobility, 6=Myle Technologies.\"),\n",
        "        bigquery.SchemaField(\"passenger_count\", \"INTEGER\",\n",
        "            description=\"N√∫mero de passageiros na corrida.\"),\n",
        "        bigquery.SchemaField(\"total_amount\", \"FLOAT\",\n",
        "            description=\"Valor total da corrida (taxas e gorjetas inclu√≠das).\"),\n",
        "        bigquery.SchemaField(\"tpep_pickup_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de in√≠cio da corrida.\"),\n",
        "        bigquery.SchemaField(\"tpep_dropoff_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de t√©rmino da corrida.\"),\n",
        "    ],\n",
        "    \"green\": [\n",
        "        bigquery.SchemaField(\"VendorID\", \"INTEGER\",\n",
        "            description=\"C√≥digo do provedor (1, 2 ou 6).\"),\n",
        "        bigquery.SchemaField(\"passenger_count\", \"INTEGER\",\n",
        "            description=\"Quantidade de passageiros.\"),\n",
        "        bigquery.SchemaField(\"total_amount\", \"FLOAT\",\n",
        "            description=\"Valor total pago.\"),\n",
        "        bigquery.SchemaField(\"tpep_pickup_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de in√≠cio da corrida.\"),\n",
        "        bigquery.SchemaField(\"tpep_dropoff_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de t√©rmino da corrida.\"),\n",
        "    ],\n",
        "    \"fhv\": [\n",
        "        bigquery.SchemaField(\"tpep_pickup_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de in√≠cio da viagem FHV.\"),\n",
        "        bigquery.SchemaField(\"tpep_dropoff_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de t√©rmino da viagem FHV.\"),\n",
        "    ],\n",
        "    \"fhvhv\": [\n",
        "        bigquery.SchemaField(\"tpep_pickup_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de in√≠cio da viagem FHVHV.\"),\n",
        "        bigquery.SchemaField(\"tpep_dropoff_datetime\", \"TIMESTAMP\",\n",
        "            description=\"Data/hora de t√©rmino da viagem FHVHV.\"),\n",
        "    ],\n",
        "}\n",
        "\n",
        "# === NORMALIZA√á√ÉO M√çNIMA POR TIPO (apenas tipos e nomes) ===\n",
        "def normalize_by_type(df, t: str):\n",
        "    if t in [\"yellow\", \"green\"]:\n",
        "        return df.select(\n",
        "            F.col(\"VendorID\").cast(\"int\").alias(\"VendorID\"),\n",
        "            F.col(\"passenger_count\").cast(\"int\").alias(\"passenger_count\"),\n",
        "            F.col(\"total_amount\").cast(\"double\").alias(\"total_amount\"),\n",
        "            F.col(\"tpep_pickup_datetime\").cast(\"timestamp\").alias(\"tpep_pickup_datetime\"),\n",
        "            F.col(\"tpep_dropoff_datetime\").cast(\"timestamp\").alias(\"tpep_dropoff_datetime\"),\n",
        "        )\n",
        "    else:  # fhv / fhvhv\n",
        "        return df.select(\n",
        "            F.col(\"tpep_pickup_datetime\").cast(\"timestamp\").alias(\"tpep_pickup_datetime\"),\n",
        "            F.col(\"tpep_dropoff_datetime\").cast(\"timestamp\").alias(\"tpep_dropoff_datetime\"),\n",
        "        )\n",
        "\n",
        "# === CRIA/RECRIA TABELA COM DESCRI√á√ïES, PARTICIONAMENTO E CLUSTERIZA√á√ÉO ===\n",
        "def create_table_with_schema(t: str):\n",
        "    table_id = f\"{PROJECT_ID}.{DATASET_ID}.tbl_{t}_bronze\"\n",
        "    table = bigquery.Table(table_id, schema=schemas[t])\n",
        "    table.description = f\"Tabela BRONZE {t.upper()} normalizada a partir da staging (tipos e nomes padronizados).\"\n",
        "    table.time_partitioning = bigquery.TimePartitioning(\n",
        "        type_=bigquery.TimePartitioningType.MONTH, field=\"tpep_pickup_datetime\"\n",
        "    )\n",
        "    if t in [\"yellow\", \"green\"]:\n",
        "        table.clustering_fields = [\"VendorID\"]\n",
        "\n",
        "    # recria para garantir que descri√ß√µes/partitioning/cluster estejam atualizados\n",
        "    bq_client.delete_table(table_id, not_found_ok=True)\n",
        "    bq_client.create_table(table)\n",
        "    print(f\"üÜï Tabela criada: {table_id}\")\n",
        "\n",
        "# === PIPELINE: LER STAGING ‚Üí NORMALIZAR ‚Üí CRIAR TABELA ‚Üí GRAVAR NO BQ ===\n",
        "for t in TYPES:\n",
        "    try:\n",
        "        print(f\"\\nüîÑ Processando tipo: {t}\")\n",
        "        path = f\"gs://{BUCKET_NAME}/{STG_PREFIX}/2023/*/{t}_tripdata_*.parquet\"\n",
        "        df_raw = spark.read.parquet(path)\n",
        "\n",
        "        df_bronze = normalize_by_type(df_raw, t)\n",
        "        print(f\"Total de linhas ({t}): {df_bronze.count()}\")\n",
        "\n",
        "        create_table_with_schema(t)\n",
        "\n",
        "        writer = (\n",
        "            df_bronze.write\n",
        "            .format(\"bigquery\")\n",
        "            .option(\"table\", f\"{PROJECT_ID}.{DATASET_ID}.tbl_{t}_bronze\")\n",
        "            .option(\"writeMethod\", \"direct\")\n",
        "            .mode(\"overwrite\")  # substitui os dados; a estrutura/descri√ß√µes ficam\n",
        "        )\n",
        "        if t in [\"yellow\", \"green\"]:\n",
        "            writer = writer.option(\"clusteredFields\", \"VendorID\") \\\n",
        "                           .option(\"partitionField\", \"tpep_pickup_datetime\") \\\n",
        "                           .option(\"partitionType\", \"MONTH\")\n",
        "\n",
        "        writer.save()\n",
        "        print(f\"Dados gravados: {PROJECT_ID}.{DATASET_ID}.tbl_{t}_bronze\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao processar {t}: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxTQHRZVl-wK"
      },
      "source": [
        "6-Ingest√£o Camada Silver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fL-Dp7YdXVR"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=\"potent-poetry-295317\")\n",
        "\n",
        "bronze = \"potent-poetry-295317.nyc_tlc_bronze\"\n",
        "silver = \"potent-poetry-295317.nyc_tlc_silver\"\n",
        "\n",
        "# Descri√ß√µes por tabela\n",
        "descriptions = {\n",
        "    \"yellow\": \"Tabela Silver com dados tratados dos t√°xis amarelos (Yellow Cabs) de NYC.\",\n",
        "    \"green\": \"Tabela Silver com dados tratados dos t√°xis verdes (Green Cabs) de NYC.\",\n",
        "    \"fhv\": \"Tabela Silver com dados tratados dos ve√≠culos FHV (For-Hire Vehicles).\",\n",
        "    \"fhvhv\": \"Tabela Silver com dados tratados dos ve√≠culos FHVHV (High Volume FHV).\"\n",
        "}\n",
        "\n",
        "# Descri√ß√µes por coluna separadas por tabela\n",
        "column_descriptions_by_table = {\n",
        "    \"yellow\": {\n",
        "        \"datetime_pickup\": \"Data e hora de in√≠cio da corrida.\",\n",
        "        \"datetime_dropoff\": \"Data e hora de t√©rmino da corrida.\",\n",
        "        \"count_passenger\": \"Quantidade de passageiros transportados na corrida.\",\n",
        "        \"id_vendor\": \"C√≥digo da empresa de t√°xi que providenciou a corrida.\",\n",
        "        \"nm_vendor\": \"Nome da empresa correspondente ao VendorID.\",\n",
        "        \"vl_amount\": \"Valor total pago pela corrida, incluindo taxas e gorjetas.\",\n",
        "        \"minutes_duration_trip\": \"Dura√ß√£o da corrida em minutos.\"\n",
        "    },\n",
        "    \"green\": {\n",
        "        \"datetime_pickup\": \"Data e hora de in√≠cio da corrida.\",\n",
        "        \"datetime_dropoff\": \"Data e hora de t√©rmino da corrida.\",\n",
        "        \"count_passenger\": \"Quantidade de passageiros transportados na corrida.\",\n",
        "        \"id_vendor\": \"C√≥digo da empresa de t√°xi que providenciou a corrida.\",\n",
        "        \"nm_vendor\": \"Nome da empresa correspondente ao VendorID.\",\n",
        "        \"vl_amount\": \"Valor total pago pela corrida, incluindo taxas e gorjetas.\",\n",
        "        \"minutes_duration_trip\": \"Dura√ß√£o da corrida em minutos.\"\n",
        "    },\n",
        "    \"fhv\": {\n",
        "        \"datetime_pickup\": \"Data e hora de in√≠cio da corrida.\",\n",
        "        \"datetime_dropoff\": \"Data e hora de t√©rmino da corrida.\",\n",
        "        \"minutes_duration_trip\": \"Dura√ß√£o da corrida em minutos.\"\n",
        "    },\n",
        "    \"fhvhv\": {\n",
        "        \"datetime_pickup\": \"Data e hora de in√≠cio da corrida.\",\n",
        "        \"datetime_dropoff\": \"Data e hora de t√©rmino da corrida.\",\n",
        "        \"minutes_duration_trip\": \"Dura√ß√£o da corrida em minutos.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Queries para recriar tabelas Silver\n",
        "queries = {\n",
        "    \"yellow\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {silver}.tbl_yellow_silver\n",
        "        PARTITION BY DATE(datetime_pickup)\n",
        "        CLUSTER BY id_vendor\n",
        "        OPTIONS(description=\\\"{descriptions['yellow']}\\\") AS\n",
        "        SELECT\n",
        "            CAST(tpep_pickup_datetime AS TIMESTAMP) AS datetime_pickup,\n",
        "            CAST(tpep_dropoff_datetime AS TIMESTAMP) AS datetime_dropoff,\n",
        "            IF(passenger_count < 0, 0, CAST(passenger_count AS INT64)) AS count_passenger,\n",
        "            CAST(VendorID AS INT64) AS id_vendor,\n",
        "            CASE\n",
        "                WHEN VendorID = 1 THEN 'Creative Mobile Technologies, LLC'\n",
        "                WHEN VendorID = 2 THEN 'Curb Mobility, LLC'\n",
        "                WHEN VendorID = 6 THEN 'Myle Technologies Inc.'\n",
        "                ELSE 'Desconhecido'\n",
        "            END AS nm_vendor,\n",
        "            IFNULL(CAST(total_amount AS FLOAT64), 0.0) AS vl_amount,\n",
        "            ROUND(TIMESTAMP_DIFF(tpep_dropoff_datetime, tpep_pickup_datetime, SECOND) / 60, 2) AS minutes_duration_trip\n",
        "        FROM {bronze}.tbl_yellow_bronze\n",
        "        WHERE DATE(tpep_pickup_datetime) BETWEEN '2023-01-01' AND '2023-05-31'\n",
        "    \"\"\",\n",
        "\n",
        "    \"green\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {silver}.tbl_green_silver\n",
        "        PARTITION BY DATE(datetime_pickup)\n",
        "        CLUSTER BY id_vendor\n",
        "        OPTIONS(description=\\\"{descriptions['green']}\\\") AS\n",
        "        SELECT\n",
        "            CAST(tpep_pickup_datetime AS TIMESTAMP) AS datetime_pickup,\n",
        "            CAST(tpep_dropoff_datetime AS TIMESTAMP) AS datetime_dropoff,\n",
        "            IF(passenger_count < 0, 0, CAST(passenger_count AS INT64)) AS count_passenger,\n",
        "            CAST(VendorID AS INT64) AS id_vendor,\n",
        "            CASE\n",
        "                WHEN VendorID = 1 THEN 'Creative Mobile Technologies, LLC'\n",
        "                WHEN VendorID = 2 THEN 'Curb Mobility, LLC'\n",
        "                WHEN VendorID = 6 THEN 'Myle Technologies Inc.'\n",
        "                ELSE 'Desconhecido'\n",
        "            END AS nm_vendor,\n",
        "            IFNULL(CAST(total_amount AS FLOAT64), 0.0) AS vl_amount,\n",
        "            ROUND(TIMESTAMP_DIFF(tpep_dropoff_datetime, tpep_pickup_datetime, SECOND) / 60, 2) AS minutes_duration_trip\n",
        "        FROM {bronze}.tbl_green_bronze\n",
        "        WHERE DATE(tpep_pickup_datetime) BETWEEN '2023-01-01' AND '2023-05-31'\n",
        "    \"\"\",\n",
        "\n",
        "    \"fhv\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {silver}.tbl_fhv_silver\n",
        "        PARTITION BY DATE(datetime_pickup)\n",
        "        OPTIONS(description=\\\"{descriptions['fhv']}\\\") AS\n",
        "        SELECT\n",
        "            CAST(tpep_pickup_datetime AS TIMESTAMP) AS datetime_pickup,\n",
        "            CAST(tpep_dropoff_datetime AS TIMESTAMP) AS datetime_dropoff,\n",
        "            ROUND(TIMESTAMP_DIFF(tpep_dropoff_datetime, tpep_pickup_datetime, SECOND) / 60, 2) AS minutes_duration_trip\n",
        "        FROM {bronze}.tbl_fhv_bronze\n",
        "        WHERE DATE(tpep_pickup_datetime) BETWEEN '2023-01-01' AND '2023-05-31'\n",
        "    \"\"\",\n",
        "\n",
        "    \"fhvhv\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {silver}.tbl_fhvhv_silver\n",
        "        PARTITION BY DATE(datetime_pickup)\n",
        "        OPTIONS(description=\\\"{descriptions['fhvhv']}\\\") AS\n",
        "        SELECT\n",
        "            CAST(tpep_pickup_datetime AS TIMESTAMP) AS datetime_pickup,\n",
        "            CAST(tpep_dropoff_datetime AS TIMESTAMP) AS datetime_dropoff,\n",
        "            ROUND(TIMESTAMP_DIFF(tpep_dropoff_datetime, tpep_pickup_datetime, SECOND) / 60, 2) AS minutes_duration_trip\n",
        "        FROM {bronze}.tbl_fhvhv_bronze\n",
        "        WHERE DATE(tpep_pickup_datetime) BETWEEN '2023-01-01' AND '2023-05-31'\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "# Executa cria√ß√£o + update de descri√ß√µes de colunas\n",
        "for tipo, query in queries.items():\n",
        "    table_id = f\"{silver}.tbl_{tipo}_silver\"\n",
        "    print(f\"Recriando tabela Silver para: {tipo}\")\n",
        "\n",
        "    client.delete_table(table_id, not_found_ok=True)\n",
        "    print(f\"Tabela deletada (se existia): {table_id}\")\n",
        "\n",
        "    client.query(query).result()\n",
        "    print(f\"Tabela {table_id} criada com sucesso.\")\n",
        "\n",
        "    table = client.get_table(table_id)\n",
        "    new_schema = []\n",
        "    column_descriptions = column_descriptions_by_table.get(tipo, {})\n",
        "    for field in table.schema:\n",
        "        desc = column_descriptions.get(field.name, field.description)\n",
        "        new_schema.append(bigquery.SchemaField(field.name, field.field_type, mode=field.mode, description=desc))\n",
        "    table.schema = new_schema\n",
        "    client.update_table(table, [\"schema\"])\n",
        "    print(f\"Descri√ß√µes de colunas aplicadas para {table_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p9l4uGcHMYB"
      },
      "source": [
        "6-Ingest√£o Camada Gold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCrcLpA6h97c",
        "outputId": "093e7cb2-704d-49ee-b78b-298460810911"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=\"potent-poetry-295317\")\n",
        "\n",
        "silver = \"potent-poetry-295317.nyc_tlc_silver\"\n",
        "gold = \"potent-poetry-295317.nyc_tlc_gold\"\n",
        "\n",
        "# Descri√ß√µes por coluna por tabela\n",
        "column_descriptions_by_table = {\n",
        "    \"tbl_yellow_gold\": {\n",
        "        \"datetime_pickup\": \"Data e hora de in√≠cio da corrida.\",\n",
        "        \"month_reference\": \"M√™s e ano da corrida (primeiro dia do m√™s).\",\n",
        "        \"avg_vl_amount\": \"Valor m√©dio total pago por corrida.\",\n",
        "        \"count_rides\": \"N√∫mero total de corridas no dia.\",\n",
        "        \"avg_minutes_duration\": \"Dura√ß√£o m√©dia das corridas no dia (em minutos).\"\n",
        "    },\n",
        "    \"tbl_green_gold\": {\n",
        "        \"datetime_pickup\": \"Data e hora de in√≠cio da corrida.\",\n",
        "        \"month_reference\": \"M√™s e ano da corrida (primeiro dia do m√™s).\",\n",
        "        \"avg_vl_amount\": \"Valor m√©dio total pago por corrida.\",\n",
        "        \"count_rides\": \"N√∫mero total de corridas no dia.\",\n",
        "        \"avg_minutes_duration\": \"Dura√ß√£o m√©dia das corridas no dia (em minutos).\"\n",
        "    },\n",
        "    \"tbl_fhv_gold\": {\n",
        "        \"datetime_pickup\": \"Data e hora de in√≠cio da corrida.\",\n",
        "        \"month_reference\": \"M√™s e ano da corrida (primeiro dia do m√™s).\",\n",
        "        \"count_rides\": \"N√∫mero total de corridas no dia.\",\n",
        "        \"avg_minutes_duration\": \"Dura√ß√£o m√©dia das corridas no dia (em minutos).\"\n",
        "    },\n",
        "    \"tbl_fhvhv_gold\": {\n",
        "        \"datetime_pickup\": \"Data e hora de in√≠cio da corrida.\",\n",
        "        \"month_reference\": \"M√™s e ano da corrida (primeiro dia do m√™s).\",\n",
        "        \"count_rides\": \"N√∫mero total de corridas no dia.\",\n",
        "        \"avg_minutes_duration\": \"Dura√ß√£o m√©dia das corridas no dia (em minutos).\"\n",
        "    },\n",
        "    \"tbl_passenger_hour_gold\": {\n",
        "        \"datetime_pickup\": \"Data e hora de in√≠cio da corrida.\",\n",
        "        \"date_reference\": \"Data da corrida.\",\n",
        "        \"month_reference\": \"M√™s e ano de refer√™ncia (primeiro dia do m√™s).\",\n",
        "        \"hour_trip\": \"Hora do dia formatada no formato HH:00 (24h) em que a corrida iniciou.\",\n",
        "        \"type_service\": \"Tipo de servi√ßo (yellow ou green).\",\n",
        "        \"avg_count_passenger\": \"M√©dia de passageiros por corrida naquela hora.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "descriptions = {\n",
        "    \"tbl_yellow_gold\": \"Tabela Gold com m√©tricas agregadas por corrida dos t√°xis amarelos.\",\n",
        "    \"tbl_green_gold\": \"Tabela Gold com m√©tricas agregadas por corrida dos t√°xis verdes.\",\n",
        "    \"tbl_fhv_gold\": \"Tabela Gold com m√©tricas agregadas dos ve√≠culos FHV.\",\n",
        "    \"tbl_fhvhv_gold\": \"Tabela Gold com m√©tricas agregadas dos ve√≠culos FHVHV.\",\n",
        "    \"tbl_passenger_hour_gold\": \"Tabela Gold com m√©dia de passageiros por hora no m√™s de maio.\"\n",
        "}\n",
        "\n",
        "queries = {\n",
        "    \"tbl_yellow_gold\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {gold}.tbl_yellow_gold\n",
        "        PARTITION BY DATE_TRUNC(datetime_pickup, MONTH)\n",
        "        OPTIONS(description=\\\"{descriptions['tbl_yellow_gold']}\\\") AS\n",
        "        SELECT\n",
        "            datetime_pickup,\n",
        "            DATE_TRUNC(datetime_pickup, MONTH) AS month_reference,\n",
        "            ROUND(AVG(vl_amount), 2) AS avg_vl_amount,\n",
        "            COUNT(*) AS count_rides,\n",
        "            ROUND(AVG(minutes_duration_trip), 2) AS avg_minutes_duration\n",
        "        FROM {silver}.tbl_yellow_silver\n",
        "        GROUP BY datetime_pickup, month_reference\n",
        "    \"\"\",\n",
        "\n",
        "    \"tbl_green_gold\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {gold}.tbl_green_gold\n",
        "        PARTITION BY DATE_TRUNC(datetime_pickup, MONTH)\n",
        "        OPTIONS(description=\\\"{descriptions['tbl_green_gold']}\\\") AS\n",
        "        SELECT\n",
        "            datetime_pickup,\n",
        "            DATE_TRUNC(datetime_pickup, MONTH) AS month_reference,\n",
        "            ROUND(AVG(vl_amount), 2) AS avg_vl_amount,\n",
        "            COUNT(*) AS count_rides,\n",
        "            ROUND(AVG(minutes_duration_trip), 2) AS avg_minutes_duration\n",
        "        FROM {silver}.tbl_green_silver\n",
        "        GROUP BY datetime_pickup, month_reference\n",
        "    \"\"\",\n",
        "\n",
        "    \"tbl_fhv_gold\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {gold}.tbl_fhv_gold\n",
        "        PARTITION BY DATE_TRUNC(datetime_pickup, MONTH)\n",
        "        OPTIONS(description=\\\"{descriptions['tbl_fhv_gold']}\\\") AS\n",
        "        SELECT\n",
        "            datetime_pickup,\n",
        "            DATE_TRUNC(datetime_pickup, MONTH) AS month_reference,\n",
        "            COUNT(*) AS count_rides,\n",
        "            ROUND(AVG(minutes_duration_trip), 2) AS avg_minutes_duration\n",
        "        FROM {silver}.tbl_fhv_silver\n",
        "        GROUP BY datetime_pickup, month_reference\n",
        "    \"\"\",\n",
        "\n",
        "    \"tbl_fhvhv_gold\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {gold}.tbl_fhvhv_gold\n",
        "        PARTITION BY DATE_TRUNC(datetime_pickup, MONTH)\n",
        "        OPTIONS(description=\\\"{descriptions['tbl_fhvhv_gold']}\\\") AS\n",
        "        SELECT\n",
        "            datetime_pickup,\n",
        "            DATE_TRUNC(datetime_pickup, MONTH) AS month_reference,\n",
        "            COUNT(*) AS count_rides,\n",
        "            ROUND(AVG(minutes_duration_trip), 2) AS avg_minutes_duration\n",
        "        FROM {silver}.tbl_fhvhv_silver\n",
        "        GROUP BY datetime_pickup, month_reference\n",
        "    \"\"\",\n",
        "\n",
        "    \"tbl_passenger_hour_gold\": f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {gold}.tbl_passenger_hour_gold\n",
        "        PARTITION BY DATE(datetime_pickup)\n",
        "        CLUSTER BY type_service, hour_trip\n",
        "        OPTIONS(description=\\\"{descriptions['tbl_passenger_hour_gold']}\\\") AS\n",
        "        SELECT\n",
        "            datetime_pickup,\n",
        "            DATE(datetime_pickup) AS date_reference,\n",
        "            DATE_TRUNC(datetime_pickup, MONTH) AS month_reference,\n",
        "            LPAD(CAST(EXTRACT(HOUR FROM datetime_pickup) AS STRING), 2, '0') || ':00' AS hour_trip,\n",
        "            'yellow' AS type_service,\n",
        "            ROUND(AVG(count_passenger), 2) AS avg_count_passenger\n",
        "        FROM {silver}.tbl_yellow_silver\n",
        "        WHERE EXTRACT(MONTH FROM datetime_pickup) = 5\n",
        "        GROUP BY datetime_pickup, date_reference, month_reference, hour_trip\n",
        "\n",
        "        UNION ALL\n",
        "\n",
        "        SELECT\n",
        "            datetime_pickup,\n",
        "            DATE(datetime_pickup) AS date_reference,\n",
        "            DATE_TRUNC(datetime_pickup, MONTH) AS month_reference,\n",
        "            LPAD(CAST(EXTRACT(HOUR FROM datetime_pickup) AS STRING), 2, '0') || ':00' AS hour_trip,\n",
        "            'green' AS type_service,\n",
        "            ROUND(AVG(count_passenger), 2) AS avg_count_passenger\n",
        "        FROM {silver}.tbl_green_silver\n",
        "        WHERE EXTRACT(MONTH FROM datetime_pickup) = 5\n",
        "        GROUP BY datetime_pickup, date_reference, month_reference, hour_trip\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "for tbl, query in queries.items():\n",
        "    table_id = f\"{gold}.{tbl}\"\n",
        "    print(f\"Criando tabela GOLD: {table_id}\")\n",
        "\n",
        "    client.delete_table(table_id, not_found_ok=True)\n",
        "    print(f\"Tabela deletada (se existia): {table_id}\")\n",
        "\n",
        "    client.query(query).result()\n",
        "    print(f\"Tabela criada com sucesso: {table_id}\")\n",
        "\n",
        "    table = client.get_table(table_id)\n",
        "    schema = []\n",
        "    col_descriptions = column_descriptions_by_table.get(tbl, {})\n",
        "    for field in table.schema:\n",
        "        desc = col_descriptions.get(field.name, field.description)\n",
        "        schema.append(bigquery.SchemaField(field.name, field.field_type, mode=field.mode, description=desc))\n",
        "    table.schema = schema\n",
        "    client.update_table(table, [\"schema\"])\n",
        "    print(f\"Descri√ß√µes de colunas atualizadas: {table_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HisZFRsn5_B4"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "name": "teste_ifood",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
